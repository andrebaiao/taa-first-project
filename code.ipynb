{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pprint\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Neural Networks\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_train.csv\")\n",
    "data_test = pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop(columns=['label'])\n",
    "y_train = data_train['label']\n",
    "\n",
    "X_test = data_test.drop(columns=['label'])\n",
    "y_test = data_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_letter(number):\n",
    "    return chr(ord('A')+number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = data_train.groupby('label', group_keys=False).apply(lambda df: df.sample(1))\n",
    "labels = sample_images['label']\n",
    "images = sample_images.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "columns = 6\n",
    "fig, axs = plt.subplots(rows,columns, figsize=(12,12))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        image_array = images.iloc[i*columns+j].values.reshape(28,28)\n",
    "        axs[i][j].imshow(image_array, cmap='gray')\n",
    "        axs[i][j].set_title(number_to_letter(labels.iloc[i*columns+j]))\n",
    "        axs[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image (h=28px, w=28px, canal=1)\n",
    "X_train_reshaped = X_train_scaled.reshape(-1,28,28,1)\n",
    "X_test_reshaped = X_test_scaled.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: the actual num_classes should be 24, but class 9 is missing.\n",
    "# Therefore the number of classes was increased to 25.\n",
    "num_classes = 25\n",
    "y_train_categorical = to_categorical(y_train, num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning Model - Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_algorithm_test(my_epochs=10):\n",
    "    epochs = my_epochs\n",
    "    batch_size = 1000\n",
    "    my_dropout=0.25\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(my_dropout))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3) ,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(my_dropout))\n",
    "    \n",
    "    #model.add(Conv2D(300, kernel_size=(3,3) ,activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(my_dropout))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(my_dropout))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train_reshaped, y_train_categorical,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "    \n",
    "    predictions = model.predict(X_test_reshaped)\n",
    "    score = model.evaluate(X_test_reshaped, y_test_categorical, verbose=0)\n",
    "    print('Test loss:{}, accuracy:{}'.format(score[0], score[1]))\n",
    "    return history, score[0], score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_algorithm(X,y,dropout,max_pooling,conv2d,batch_size=1000,epochs=20): # tinha x e y nos argumentos\n",
    "        # Normalization\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaler.fit(X)\n",
    "        X_train_scaled = scaler.transform(X)\n",
    "\n",
    "        # Reshape image (h=28px, w=28px, canal=1)\n",
    "        X_train_reshaped = X_train_scaled.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        num_classes = 25\n",
    "        # one hot encode our y variables\n",
    "        y_train_categorical = to_categorical(y, num_classes)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(conv2d, kernel_size=(3, 3),\n",
    "                         activation='relu',\n",
    "                         input_shape=(28,28,1)))\n",
    "        model.add(MaxPooling2D(pool_size=(max_pooling, max_pooling)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Conv2D(filters=conv2d,\n",
    "                              kernel_size=6,\n",
    "                              activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(max_pooling, max_pooling)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(X_train_reshaped, y_train_categorical,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1)\n",
    "        \n",
    "        predictions = model.predict(X_test_reshaped)\n",
    "        score = model.evaluate(X_test_reshaped, y_test_categorical, verbose=0)\n",
    "        #print('Test loss:{}, accuracy:{}'.format(score[0], score[1]))\n",
    "        # eturn history, score[0], score[1]\n",
    "        return history,model,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_several_dropout():\n",
    "        DROPOUTS = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4 , 0.45, 0.5]\n",
    "        results = []\n",
    "        for d in DROPOUTS:    \n",
    "            _, l, res = cnn_algorithm(d)\n",
    "            results.append(res)\n",
    "        for i in range(len(results)):\n",
    "            print(\"Acc: {}  Drop: {}\".format(results[i], DROPOUTS[i]))\n",
    "        plt.plot(DROPOUTS, results)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def test_several_epochs():\n",
    "        EPOCHS = [10, 20, 30,40,50,60, 80]\n",
    "        combination = [(0.3, 312, 3)]\n",
    "        \n",
    "        my_acc = []\n",
    "        my_loss = []\n",
    "        mean_acc = []\n",
    "        COUNT = 5\n",
    "        for e in EPOCHS:   \n",
    "            for i in range(COUNT):\n",
    "                _,_,a=cnn_algorithm(dropout=combination[0][0],max_pooling=combination[0][2],conv2d=combination[0][1], epochs=e)\n",
    "                my_acc.append(a)\n",
    "            mean_acc.append(np.mean(my_acc))\n",
    "            my_acc = []\n",
    "        plt.plot(EPOCHS,mean_acc, label=\"accuracy\")\n",
    "        plt.title(\"Score across different epochs\")\n",
    "        plt.legend([\"accuracy\", \"loss\"])\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def test_several_batchsize():\n",
    "        BATCHSIZE = [100, 1000, 3000,5000,10000]\n",
    "        my_acc = []\n",
    "        my_loss = []\n",
    "        for b in BATCHSIZE:    \n",
    "            _,l,a = cnn_algorithm(b)\n",
    "            my_acc.append(a)\n",
    "            my_loss.append(l)\n",
    "        plt.plot(BATCHSIZE,my_acc, label=\"accuracy\")\n",
    "        plt.plot(BATCHSIZE,my_loss, label=\"loss\")\n",
    "        plt.title(\"Score across different batch sizes\")\n",
    "        plt.legend([\"accuracy\", \"loss\"])\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateKFolds(X, y, realTestX, realTestY, splits, examples=[300], combinations=[]):\n",
    "        # Initialize data\n",
    "        validationScores={i:[] for i in combinations}\n",
    "        trainScores={i:[] for i in combinations}\n",
    "        testScores={i:[] for i in combinations}\n",
    "        for training_samples in examples:\n",
    "            kfold = KFold(n_splits=splits)\n",
    "            for dropout,conv2d,max_pooling in combinations:\n",
    "                for train_index, test_index in kfold.split(X[:training_samples]):\n",
    "                    print(f\"Train index {train_index}\")\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "                    #history,model,scaler=self.cnn_algorithm(X=X_train,y=y_train,epochs=10,batch_size=1000)\n",
    "                    history,model,scaler=cnn_algorithm(X=X_train,y=y_train,dropout=dropout,max_pooling=max_pooling,conv2d=conv2d)\n",
    "\n",
    "                    X_test_scaled = scaler.transform(X_test)\n",
    "                    X_test_reshaped = X_test_scaled.reshape(-1,28,28,1)\n",
    "                    y_test_categorical = to_categorical(y_test,25) #Need to reshape to 25 because there are 2 classes missing\n",
    "\n",
    "                    trainScores[(dropout,conv2d,max_pooling)].append(history.history[\"accuracy\"][-1])\n",
    "                    validationScores[(dropout,conv2d,max_pooling)].append(model.evaluate(X_test_reshaped,y_test_categorical)[1])\n",
    "\n",
    "                history,model,scaler=cnn_algorithm(X=X,y=y,dropout=dropout,max_pooling=max_pooling,conv2d=conv2d)\n",
    "                testScores[(dropout,conv2d,max_pooling)].append(model.evaluate(realTestX, realTestY)[1])\n",
    "\n",
    "        #print(f\"Validation scores (Accuracy) {validationScores}\")\n",
    "        #print(f\"Train scores (Accuracy){trainScores}\")\n",
    "        mean_val_sample = {i:np.mean(validationScores[i]) for i in validationScores}\n",
    "        mean_train_sample = {i:np.mean(trainScores[i]) for i in trainScores}\n",
    "        mean_per_val_sample = [np.mean(validationScores[i]) for i in validationScores]\n",
    "        mean_per_train_sample = [np.mean(trainScores[i]) for i in trainScores]\n",
    "        #print(mean_val_sample)\n",
    "        #print(mean_train_sample)\n",
    "        x_values = [str(i[:]) for i in combinations]\n",
    "        plt.figure(num=1,figsize=(8,10),dpi=1200)\n",
    "        plt.rcParams.update({'font.size':12})\n",
    "        plt.plot(x_values,mean_per_val_sample,label=\"validation accuracy\")\n",
    "        plt.plot(x_values,mean_per_train_sample,label=\"train accuracy\",linestyle=\"-.\")\n",
    "        plt.plot(x_values,list(testScores.values()),label=\"test accuracy\",linestyle=\"--\")\n",
    "        plt.xlabel(\"Training examples (Dropout,Max Pooling,Conv2d) \")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(f\"K-Fold with {splits} splits\")\n",
    "        plt.show()\n",
    "        return testScores,trainScores,validationScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history, score_zero, score_um = cnn_algorithm()\n",
    "#test_several_dropout()\n",
    "#test_several_batchsize()\n",
    "#test_several_epochs()\n",
    "dropout=[0,0.2,0.3,0.4,0.5]\n",
    "conv2d=[32,124,312]\n",
    "maxpooling=[2,3]\n",
    "combinations=[(d,c,m) for d in dropout for c in conv2d for m in maxpooling]\n",
    "generateKFolds(X_train.values, y_train.values,X_test_reshaped,y_test_categorical,splits=5,examples=[27455],combinations=combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history,model,scaler=cnn_algorithm(X=X_train.values,y=y_train.values,dropout=0.4,max_pooling=3,conv2d=312)\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "\n",
    "\n",
    "true_values=[y_test[i] for i in range(len(y_test))]\n",
    "pred_values=model.predict_classes(X_test_reshaped)\n",
    "confusion=confusion_matrix(true_values,pred_values)\n",
    "letters=['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "ignore_zeros=[count_test_labels[i] for i in letters]\n",
    "confusion2=[list(np.divide(confusion[i],ignore_zeros[i])) for i in range(len(confusion))]\n",
    "df_cm = pd.DataFrame(confusion2, letters, letters)\n",
    "plt.figure(figsize=(20,20))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm,annot=True, annot_kws={\"size\": 10},fmt=\".3g\") # font size\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Real Value')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Cost Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_labels = pd.Series([p.argmax() for p in predictions])\n",
    "dict_pred_labels=preds_labels.to_dict()\n",
    "# Series containing only the mislabeled elements\n",
    "failed_preds = {i:dict_pred_labels[i] for i in dict_pred_labels if dict_pred_labels[i]!=y_test[i]}\n",
    "count={}\n",
    "print(len(failed_preds))\n",
    "for i in failed_preds:\n",
    "    if number_to_letter(y_test[i]) in count:\n",
    "        if number_to_letter(failed_preds[i]) in count[number_to_letter(y_test[i])]:\n",
    "            count[number_to_letter(y_test[i])][number_to_letter(failed_preds[i])]+=1\n",
    "        else:\n",
    "            count[number_to_letter(y_test[i])]=dict(count[number_to_letter(y_test[i])],**{number_to_letter(failed_preds[i]):1})\n",
    "    else:\n",
    "        count[number_to_letter(y_test[i])]={number_to_letter(failed_preds[i]):1}\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_labels = pd.Series([p.argmax() for p in predictions])\n",
    "\n",
    "# Series containing only the mislabeled elements\n",
    "failed_preds = preds_labels[preds_labels != y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "columns = 6\n",
    "fig, axs = plt.subplots(rows,columns, figsize=(12,12))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        index = failed_preds.index[i*columns+j]\n",
    "        image_array = X_test.loc[index].values.reshape(28,28)\n",
    "        axs[i][j].imshow(image_array, cmap='gray')\n",
    "        axs[i][j].set_title('Label: {}\\n Predicted: {}'.format(number_to_letter(y_test.loc[index]),\n",
    "                                                               number_to_letter(predictions[index].argmax())))\n",
    "        axs[i][j].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
